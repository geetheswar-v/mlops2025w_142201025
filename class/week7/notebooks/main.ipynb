{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a22bc45",
   "metadata": {},
   "source": [
    "# Snorkel on IMDB\n",
    "\n",
    "## 1. Load and Explore IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load IMDb dataset\n",
    "imdb = load_dataset(\"stanfordnlp/imdb\")\n",
    "\n",
    "# Select subsets for faster experimentation\n",
    "train = pd.DataFrame(imdb[\"train\"].select(range(2000)))\n",
    "test = pd.DataFrame(imdb[\"test\"].select(range(500)))\n",
    "\n",
    "print(\"Train size:\", len(train), \"Test size:\", len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c603a13d",
   "metadata": {},
   "source": [
    "## 2. Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b114d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n",
    "    text = re.sub(r\"[^\\w\\s']\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(clean_text)\n",
    "test[\"text\"] = test[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494380c",
   "metadata": {},
   "source": [
    "## 3. Define Labeling Functions (LFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b527f",
   "metadata": {},
   "source": [
    "### We’ll define simple heuristics to generate weak labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee13a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function, LFAnalysis, PandasLFApplier, LabelModel\n",
    "\n",
    "ABSTAIN, NEG, POS = -1, 0, 1\n",
    "\n",
    "positive_words = {\"great\", \"excellent\", \"amazing\", \"wonderful\", \"best\", \"fantastic\"}\n",
    "negative_words = {\"bad\", \"terrible\", \"awful\", \"worst\", \"boring\", \"poor\"}\n",
    "\n",
    "@labeling_function()\n",
    "def lf_positive(x):\n",
    "    return POS if any(w in x.text.split() for w in positive_words) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_negative(x):\n",
    "    return NEG if any(w in x.text.split() for w in negative_words) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def lf_exclaim(x):\n",
    "    return POS if x.text.count(\"!\") > 2 else ABSTAIN\n",
    "\n",
    "lfs = [lf_positive, lf_negative, lf_exclaim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72542b8",
   "metadata": {},
   "source": [
    "### Analyze LF Coverage & Conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(train)\n",
    "\n",
    "LFAnalysis(L_train, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31443092",
   "metadata": {},
   "source": [
    "## 4. Train the Label Model\n",
    "\n",
    "Snorkel combines LFs into a probabilistic label source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=42)\n",
    "\n",
    "# Get weak labels\n",
    "train_probs = label_model.predict_proba(L_train)\n",
    "train_preds = label_model.predict(L_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b5e026",
   "metadata": {},
   "source": [
    "## 5. Train End-to-End Classifier on Weak Labels\n",
    "\n",
    "We’ll use a simple TF-IDF + Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13064429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train[\"text\"])\n",
    "y_train = train_preds\n",
    "\n",
    "# Train classifier using weak labels\n",
    "clf = LogisticRegression(max_iter=200)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "X_test = vectorizer.transform(test[\"text\"])\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Weakly Supervised Performance:\")\n",
    "print(classification_report(y_test, preds, target_names=[\"neg\", \"pos\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1b77a",
   "metadata": {},
   "source": [
    "## 6. Compare with Fully Supervised Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_fs = LogisticRegression(max_iter=200)\n",
    "clf_fs.fit(X_train, train[\"label\"])\n",
    "fs_preds = clf_fs.predict(X_test)\n",
    "\n",
    "print(\"Fully Supervised Performance:\")\n",
    "print(classification_report(y_test, fs_preds, target_names=[\"neg\", \"pos\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2f5a",
   "metadata": {},
   "source": [
    "## 7. Visualize Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak supervision confusion matrix\n",
    "cm_weak = confusion_matrix(y_test, preds)\n",
    "# Fully supervised confusion matrix\n",
    "cm_full = confusion_matrix(y_test, fs_preds)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "sns.heatmap(cm_weak, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax[0])\n",
    "ax[0].set_title(\"Weakly Supervised\")\n",
    "ax[0].set_xlabel(\"Predicted\")\n",
    "ax[0].set_ylabel(\"True\")\n",
    "\n",
    "sns.heatmap(cm_full, annot=True, fmt=\"d\", cmap=\"Greens\", ax=ax[1])\n",
    "ax[1].set_title(\"Fully Supervised\")\n",
    "ax[1].set_xlabel(\"Predicted\")\n",
    "ax[1].set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e2871",
   "metadata": {},
   "source": [
    "## Coverage–Accuracy Trade-Off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = LFAnalysis(L_train, lfs).lf_summary()\n",
    "sns.scatterplot(x=\"Coverage\", y=\"Emp. Acc.\", data=summary)\n",
    "plt.title(\"LF Coverage vs Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8d080b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "class-work (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
